{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "\n",
    "from CharToIndex import CharToIndex\n",
    "from MyDatasets import BaseDataset as MyDataset\n",
    "from MyCustomLayer import CharToVectorLayer \n",
    "\n",
    "\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_file_path = \"/net/nfs2/export/home/ohno/CR_pytorch/data/main/all_chars.npy\"\n",
    "tokens = CharToIndex(chars_file_path)\n",
    "data_file_path = \"/net/nfs2/export/home/ohno/CR_pytorch/data/main/origin.npy\"\n",
    "data = np.load(data_file_path,allow_pickle=True)\n",
    "\n",
    "EMBEDDING_DIM = 10\n",
    "HIDDEN_SIZE = 300\n",
    "BATCH_SIZE = 1\n",
    "VOCAB_SIZE = len(tokens)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = MyDataset(data,chars_file_path,device=device)\n",
    "\n",
    "def split_dataset(dataest,train_valid_ratio=None):\n",
    "    assert type(train_valid_ratio)==tuple\n",
    "    assert type(train_valid_ratio[0])==int and type(train_valid_ratio[1])==int \n",
    "    assert train_valid_ratio[0]+train_valid_ratio[1]==10 \n",
    "\n",
    "    whole_length = len(dataset)\n",
    "    indices_sets = []\n",
    "    pre_point = 0\n",
    "    split_num = 10\n",
    "    sets_length = int(whole_length/split_num)\n",
    "    valid_ratio = train_valid_ratio[1]\n",
    "\n",
    "    for i in range(split_num):\n",
    "        indices_sets.append(list(range(pre_point,pre_point+sets_length)))\n",
    "        pre_point+=sets_length\n",
    "\n",
    "    import random\n",
    "    import itertools\n",
    "    random_sets = random.sample(indices_sets,split_num) \n",
    "    valid_indices = list(itertools.chain.from_iterable(random_sets[:valid_ratio]))\n",
    "    train_indices = list(itertools.chain.from_iterable(random_sets[valid_ratio:]))\n",
    "\n",
    "    from torch.utils.data import Subset\n",
    "    valid_dataset = Subset(dataset,valid_indices)\n",
    "    train_dataset = Subset(dataset,train_indices)\n",
    "    \n",
    "    return train_dataset,valid_dataset\n",
    "\n",
    "\n",
    "train_dataset, valid_dataset = split_dataset(dataset,train_valid_ratio=(9,1)) #データセットを訓練、検証用に分割\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,drop_last=True) #訓練データのみシャッフル\n",
    "valid_dataloader=DataLoader(valid_dataset,batch_size=BATCH_SIZE,shuffle=False,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharToVectorLayer3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vec_of_char = torch.load(\"/net/nfs2/export/home/ohno/CR_pytorch/data/main/char2vec\")\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #(1,5,10)\n",
    "        output = []\n",
    "        for timestep_item in x:\n",
    "            timesteps_list = []\n",
    "            for feature_item in timestep_item:\n",
    "                features_list = []\n",
    "                for f in feature_item:\n",
    "                    features_list.append(self.vec_of_char[f.item()])\n",
    "                timesteps_list.append(torch.stack(features_list,0))\n",
    "            output.append(torch.stack(timesteps_list,0))\n",
    "        \n",
    "        return torch.stack(output,0).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "layer = CharToVectorLayer3()\n",
    "for x,y in valid_dataloader:\n",
    "    output = layer(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:torch.Size([64, 5, 10, 5])\n",
      "torch.Size([64, 5, 10, 1])\n",
      "torch.Size([64, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "timesteps_size=5\n",
    "features_size=10\n",
    "vector_size = 5\n",
    "m = nn.Linear(vector_size, 1)\n",
    "input = torch.randn(batch_size,timesteps_size,features_size,vector_size)\n",
    "print(f'input size:{input.size()}')\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "print(torch.squeeze(output).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3f068fdb30bfe91116931ab9f38f90abd8ac3f51d16a38a70c3d538a36b3166"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('CR_pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
