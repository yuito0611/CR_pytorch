DetectorとProofreaderを組み合わせた時の性能
共通条件：  Proofreader->RNN1層、WeightedTenHotEncode N=5,
            Detector->WeightedTenhotEncode,NN2層、二値分類

〇N=5
accuracy :  [0.8410326,0.857337,0.8688859,0.8491848,0.8009511,0.7221467,0.9014946,0.9293478,0.9021739,0.9252717]
acc average:0.8597826100000001


〇N=5
Cross Validation: k=[1/10]

 epoch:[ 10/100]
  Detector| loss:0.11284, accu:0.95517, val_accu:0.83288
  Proof   | loss:0.79887, accu:0.86127, val_accu:0.7663

 epoch:[ 20/100]
  Detector| loss:0.063026, accu:0.97371, val_accu:0.84375
  Proof   | loss:0.59037, accu:0.88902, val_accu:0.77514

 epoch:[ 30/100]
  Detector| loss:0.042122, accu:0.98306, val_accu:0.84443
  Proof   | loss:0.54724, accu:0.89815, val_accu:0.78668

 epoch:[ 40/100]
  Detector| loss:0.040954, accu:0.9862, val_accu:0.84647
  Proof   | loss:0.47332, accu:0.90552, val_accu:0.78465

 epoch:[ 50/100]
  Detector| loss:0.031065, accu:0.98839, val_accu:0.84579
  Proof   | loss:0.43065, accu:0.91596, val_accu:0.78736

 epoch:[ 60/100]
  Detector| loss:0.029215, accu:0.98941, val_accu:0.84715
  Proof   | loss:0.38319, accu:0.91757, val_accu:0.78533

 epoch:[ 70/100]
  Detector| loss:0.02998, accu:0.98876, val_accu:0.84783
  Proof   | loss:0.39183, accu:0.92261, val_accu:0.78329

 epoch:[ 80/100]
  Detector| loss:0.026501, accu:0.99036, val_accu:0.84375
  Proof   | loss:0.35228, accu:0.92881, val_accu:0.80027

 epoch:[ 90/100]
  Detector| loss:0.023639, accu:0.99109, val_accu:0.84715
  Proof   | loss:0.31952, accu:0.9337, val_accu:0.78533

 epoch:[100/100]
  Detector| loss:0.025, accu:0.99131, val_accu:0.84239
  Proof   | loss:0.2986, accu:0.9364, val_accu:0.80027
 examin accuracy:0.8410326

Cross Validation: k=[2/10]

 epoch:[ 10/100]
  Detector| loss:0.11967, accu:0.95378, val_accu:0.84986
  Proof   | loss:0.80653, accu:0.86127, val_accu:0.74524

 epoch:[ 20/100]
  Detector| loss:0.063498, accu:0.97466, val_accu:0.84783
  Proof   | loss:0.58713, accu:0.88865, val_accu:0.76223

 epoch:[ 30/100]
  Detector| loss:0.046242, accu:0.98131, val_accu:0.83967
  Proof   | loss:0.51237, accu:0.898, val_accu:0.75815

 epoch:[ 40/100]
  Detector| loss:0.034984, accu:0.98489, val_accu:0.84851
  Proof   | loss:0.4827, accu:0.90494, val_accu:0.75204

 epoch:[ 50/100]
  Detector| loss:0.027898, accu:0.98927, val_accu:0.85054
  Proof   | loss:0.43528, accu:0.91392, val_accu:0.76019

 epoch:[ 60/100]
  Detector| loss:0.027906, accu:0.98876, val_accu:0.84851
  Proof   | loss:0.41355, accu:0.91589, val_accu:0.76019

 epoch:[ 70/100]
  Detector| loss:0.025451, accu:0.99022, val_accu:0.86073
  Proof   | loss:0.38984, accu:0.92122, val_accu:0.75883

 epoch:[ 80/100]
  Detector| loss:0.022625, accu:0.99073, val_accu:0.85394
  Proof   | loss:0.36299, accu:0.92282, val_accu:0.77106

 epoch:[ 90/100]
  Detector| loss:0.021807, accu:0.99109, val_accu:0.84511
  Proof   | loss:0.35184, accu:0.92553, val_accu:0.76562

 epoch:[100/100]
  Detector| loss:0.019773, accu:0.9916, val_accu:0.84783
  Proof   | loss:0.33169, accu:0.93334, val_accu:0.76155
 examin accuracy:0.857337

Cross Validation: k=[3/10]

 epoch:[ 10/100]
  Detector| loss:0.11531, accu:0.95422, val_accu:0.85666
  Proof   | loss:0.83912, accu:0.85514, val_accu:0.80163

 epoch:[ 20/100]
  Detector| loss:0.06796, accu:0.9724, val_accu:0.86957
  Proof   | loss:0.65355, accu:0.89165, val_accu:0.8159

 epoch:[ 30/100]
  Detector| loss:0.047757, accu:0.97926, val_accu:0.8587
  Proof   | loss:0.51003, accu:0.90632, val_accu:0.81997

 epoch:[ 40/100]
  Detector| loss:0.039431, accu:0.9835, val_accu:0.83356
  Proof   | loss:0.41705, accu:0.9191, val_accu:0.82337

 epoch:[ 50/100]
  Detector| loss:0.044567, accu:0.98532, val_accu:0.84918
  Proof   | loss:0.40601, accu:0.91903, val_accu:0.82473

 epoch:[ 60/100]
  Detector| loss:0.031687, accu:0.98635, val_accu:0.8519
  Proof   | loss:0.39174, accu:0.92399, val_accu:0.82745

 epoch:[ 70/100]
  Detector| loss:0.028511, accu:0.98722, val_accu:0.8587
  Proof   | loss:0.37216, accu:0.92399, val_accu:0.81793

 epoch:[ 80/100]
  Detector| loss:0.028452, accu:0.98846, val_accu:0.85938
  Proof   | loss:0.37701, accu:0.92202, val_accu:0.81726

 epoch:[ 90/100]
  Detector| loss:0.022896, accu:0.99087, val_accu:0.85054
  Proof   | loss:0.3457, accu:0.92888, val_accu:0.81182

 epoch:[100/100]
  Detector| loss:0.023605, accu:0.99029, val_accu:0.85326
  Proof   | loss:0.30326, accu:0.9348, val_accu:0.81658
 examin accuracy:0.8688859

Cross Validation: k=[4/10]

 epoch:[ 10/100]
  Detector| loss:0.12037, accu:0.95079, val_accu:0.86277
  Proof   | loss:0.78646, accu:0.86259, val_accu:0.72758

 epoch:[ 20/100]
  Detector| loss:0.066956, accu:0.97058, val_accu:0.85734
  Proof   | loss:0.57739, accu:0.88763, val_accu:0.73234

 epoch:[ 30/100]
  Detector| loss:0.050519, accu:0.97839, val_accu:0.84375
  Proof   | loss:0.5025, accu:0.90326, val_accu:0.7269

 epoch:[ 40/100]
  Detector| loss:0.038755, accu:0.98452, val_accu:0.85938
  Proof   | loss:0.44123, accu:0.9137, val_accu:0.72418

 epoch:[ 50/100]
  Detector| loss:0.034369, accu:0.98489, val_accu:0.86549
  Proof   | loss:0.38448, accu:0.92239, val_accu:0.73981

 epoch:[ 60/100]
  Detector| loss:0.02811, accu:0.98846, val_accu:0.86277
  Proof   | loss:0.3595, accu:0.93319, val_accu:0.73166

 epoch:[ 70/100]
  Detector| loss:0.024454, accu:0.99073, val_accu:0.86345
  Proof   | loss:0.27908, accu:0.94758, val_accu:0.73166

 epoch:[ 80/100]
  Detector| loss:0.023058, accu:0.99182, val_accu:0.84647
  Proof   | loss:0.25429, accu:0.95707, val_accu:0.74932

 epoch:[ 90/100]
  Detector| loss:0.019713, accu:0.99284, val_accu:0.85734
  Proof   | loss:0.23879, accu:0.96327, val_accu:0.74524

 epoch:[100/100]
  Detector| loss:0.025457, accu:0.99087, val_accu:0.84375
  Proof   | loss:0.19624, accu:0.96831, val_accu:0.74457
 examin accuracy:0.8491848

Cross Validation: k=[5/10]

 epoch:[ 10/100]
  Detector| loss:0.11032, accu:0.95444, val_accu:0.7962
  Proof   | loss:0.80621, accu:0.86273, val_accu:0.72215

 epoch:[ 20/100]
  Detector| loss:0.068307, accu:0.97313, val_accu:0.80367
  Proof   | loss:0.61745, accu:0.88529, val_accu:0.73098

 epoch:[ 30/100]
  Detector| loss:0.039399, accu:0.98335, val_accu:0.79552
  Proof   | loss:0.54321, accu:0.8953, val_accu:0.73913

 epoch:[ 40/100]
  Detector| loss:0.03881, accu:0.98503, val_accu:0.79755
  Proof   | loss:0.46571, accu:0.90822, val_accu:0.75

 epoch:[ 50/100]
  Detector| loss:0.030025, accu:0.98817, val_accu:0.80367
  Proof   | loss:0.44441, accu:0.91282, val_accu:0.72962

 epoch:[ 60/100]
  Detector| loss:0.028633, accu:0.98824, val_accu:0.79416
  Proof   | loss:0.393, accu:0.9199, val_accu:0.74389

 epoch:[ 70/100]
  Detector| loss:0.026265, accu:0.99014, val_accu:0.79688
  Proof   | loss:0.37611, accu:0.92545, val_accu:0.73709

 epoch:[ 80/100]
  Detector| loss:0.028164, accu:0.98817, val_accu:0.80571
  Proof   | loss:0.35041, accu:0.92414, val_accu:0.74049

 epoch:[ 90/100]
  Detector| loss:0.024314, accu:0.99058, val_accu:0.79891
  Proof   | loss:0.31269, accu:0.93341, val_accu:0.73913

 epoch:[100/100]
  Detector| loss:0.025536, accu:0.99138, val_accu:0.79688
  Proof   | loss:0.32486, accu:0.93275, val_accu:0.73709
 examin accuracy:0.8009511

Cross Validation: k=[6/10]

 epoch:[ 10/100]
  Detector| loss:0.11037, accu:0.95867, val_accu:0.74524
  Proof   | loss:0.96769, accu:0.84813, val_accu:0.68478

 epoch:[ 20/100]
  Detector| loss:0.068162, accu:0.97328, val_accu:0.74796
  Proof   | loss:0.60984, accu:0.89778, val_accu:0.68342

 epoch:[ 30/100]
  Detector| loss:0.052835, accu:0.97934, val_accu:0.7534
  Proof   | loss:0.49021, accu:0.91465, val_accu:0.68546

 epoch:[ 40/100]
  Detector| loss:0.042044, accu:0.98379, val_accu:0.74524
  Proof   | loss:0.39729, accu:0.93166, val_accu:0.67595

 epoch:[ 50/100]
  Detector| loss:0.031774, accu:0.98678, val_accu:0.74321
  Proof   | loss:0.34238, accu:0.94276, val_accu:0.68342

 epoch:[ 60/100]
  Detector| loss:0.033037, accu:0.98686, val_accu:0.75272
  Proof   | loss:0.28416, accu:0.9551, val_accu:0.68274

 epoch:[ 70/100]
  Detector| loss:0.031423, accu:0.98788, val_accu:0.74321
  Proof   | loss:0.25865, accu:0.96086, val_accu:0.68478

 epoch:[ 80/100]
  Detector| loss:0.024946, accu:0.99102, val_accu:0.73505
  Proof   | loss:0.23903, accu:0.96232, val_accu:0.69905

 epoch:[ 90/100]
  Detector| loss:0.023505, accu:0.99109, val_accu:0.72826
  Proof   | loss:0.2575, accu:0.96313, val_accu:0.68818

 epoch:[100/100]
  Detector| loss:0.02091, accu:0.9919, val_accu:0.74253
  Proof   | loss:0.23697, accu:0.96868, val_accu:0.69633
 examin accuracy:0.7221467

Cross Validation: k=[7/10]

 epoch:[ 10/100]
  Detector| loss:0.11638, accu:0.95203, val_accu:0.90693
  Proof   | loss:0.91334, accu:0.8485, val_accu:0.83764

 epoch:[ 20/100]
  Detector| loss:0.061757, accu:0.9762, val_accu:0.89742
  Proof   | loss:0.61066, accu:0.88332, val_accu:0.84443

 epoch:[ 30/100]
  Detector| loss:0.045757, accu:0.98218, val_accu:0.88995
  Proof   | loss:0.51958, accu:0.89778, val_accu:0.84918

 epoch:[ 40/100]
  Detector| loss:0.036489, accu:0.98489, val_accu:0.89742
  Proof   | loss:0.48203, accu:0.90508, val_accu:0.85054

 epoch:[ 50/100]
  Detector| loss:0.030966, accu:0.98759, val_accu:0.89402
  Proof   | loss:0.46605, accu:0.90997, val_accu:0.8322

 epoch:[ 60/100]
  Detector| loss:0.026847, accu:0.98956, val_accu:0.90693
  Proof   | loss:0.40153, accu:0.91983, val_accu:0.83899

 epoch:[ 70/100]
  Detector| loss:0.025382, accu:0.99029, val_accu:0.89674
  Proof   | loss:0.37084, accu:0.9218, val_accu:0.84035

 epoch:[ 80/100]
  Detector| loss:0.02041, accu:0.99263, val_accu:0.90014
  Proof   | loss:0.35794, accu:0.92589, val_accu:0.85122

 epoch:[ 90/100]
  Detector| loss:0.025069, accu:0.99211, val_accu:0.89742
  Proof   | loss:0.33805, accu:0.92823, val_accu:0.84647

 epoch:[100/100]
  Detector| loss:0.022202, accu:0.99306, val_accu:0.88995
  Proof   | loss:0.32441, accu:0.9318, val_accu:0.84579
 examin accuracy:0.9014946

Cross Validation: k=[8/10]

 epoch:[ 10/100]
  Detector| loss:0.11767, accu:0.95312, val_accu:0.92663
  Proof   | loss:0.91055, accu:0.84192, val_accu:0.8716

 epoch:[ 20/100]
  Detector| loss:0.066975, accu:0.97277, val_accu:0.91916
  Proof   | loss:0.61886, accu:0.88822, val_accu:0.87976

 epoch:[ 30/100]
  Detector| loss:0.045057, accu:0.98189, val_accu:0.92052
  Proof   | loss:0.53714, accu:0.89588, val_accu:0.89878

 epoch:[ 40/100]
  Detector| loss:0.039957, accu:0.98467, val_accu:0.92391
  Proof   | loss:0.48013, accu:0.90508, val_accu:0.88315

 epoch:[ 50/100]
  Detector| loss:0.030653, accu:0.98649, val_accu:0.91916
  Proof   | loss:0.44323, accu:0.90822, val_accu:0.88383

 epoch:[ 60/100]
  Detector| loss:0.026745, accu:0.98971, val_accu:0.91644
  Proof   | loss:0.39988, accu:0.9164, val_accu:0.89606

 epoch:[ 70/100]
  Detector| loss:0.02822, accu:0.98919, val_accu:0.91576
  Proof   | loss:0.40336, accu:0.91779, val_accu:0.8913

 epoch:[ 80/100]
  Detector| loss:0.023574, accu:0.99058, val_accu:0.91576
  Proof   | loss:0.34448, accu:0.92699, val_accu:0.89334

 epoch:[ 90/100]
  Detector| loss:0.020684, accu:0.99095, val_accu:0.92052
  Proof   | loss:0.34187, accu:0.92852, val_accu:0.88995

 epoch:[100/100]
  Detector| loss:0.028795, accu:0.99065, val_accu:0.91848
  Proof   | loss:0.31736, accu:0.93129, val_accu:0.89946
 examin accuracy:0.9293478

Cross Validation: k=[9/10]

 epoch:[ 10/100]
  Detector| loss:0.11656, accu:0.95218, val_accu:0.89538
  Proof   | loss:0.91231, accu:0.85105, val_accu:0.86345

 epoch:[ 20/100]
  Detector| loss:0.062916, accu:0.97532, val_accu:0.89878
  Proof   | loss:0.58421, accu:0.88683, val_accu:0.86753

 epoch:[ 30/100]
  Detector| loss:0.045091, accu:0.98233, val_accu:0.88723
  Proof   | loss:0.48994, accu:0.90501, val_accu:0.86821

 epoch:[ 40/100]
  Detector| loss:0.04017, accu:0.98321, val_accu:0.89062
  Proof   | loss:0.48314, accu:0.90588, val_accu:0.86957

 epoch:[ 50/100]
  Detector| loss:0.033796, accu:0.98649, val_accu:0.88655
  Proof   | loss:0.44, accu:0.91311, val_accu:0.86889

 epoch:[ 60/100]
  Detector| loss:0.028788, accu:0.98919, val_accu:0.89606
  Proof   | loss:0.42483, accu:0.91618, val_accu:0.86413

 epoch:[ 70/100]
  Detector| loss:0.023123, accu:0.99073, val_accu:0.88315
  Proof   | loss:0.37059, accu:0.92158, val_accu:0.87772

 epoch:[ 80/100]
  Detector| loss:0.022111, accu:0.99182, val_accu:0.88791
  Proof   | loss:0.35164, accu:0.92633, val_accu:0.86617

 epoch:[ 90/100]
  Detector| loss:0.024015, accu:0.99095, val_accu:0.88315
  Proof   | loss:0.32152, accu:0.93188, val_accu:0.85938

 epoch:[100/100]
  Detector| loss:0.027142, accu:0.99153, val_accu:0.88859
  Proof   | loss:0.33749, accu:0.92983, val_accu:0.86889
 examin accuracy:0.9021739

Cross Validation: k=[10/10]

 epoch:[ 10/100]
  Detector| loss:0.12103, accu:0.95123, val_accu:0.92255
  Proof   | loss:1.044, accu:0.83302, val_accu:0.85462

 epoch:[ 20/100]
  Detector| loss:0.069393, accu:0.97211, val_accu:0.89538
  Proof   | loss:0.78197, accu:0.87456, val_accu:0.85394

 epoch:[ 30/100]
  Detector| loss:0.046623, accu:0.98029, val_accu:0.90965
  Proof   | loss:0.57165, accu:0.90683, val_accu:0.86413

 epoch:[ 40/100]
  Detector| loss:0.037369, accu:0.98401, val_accu:0.88859
  Proof   | loss:0.41987, accu:0.92684, val_accu:0.87092

 epoch:[ 50/100]
  Detector| loss:0.035038, accu:0.98569, val_accu:0.89402
  Proof   | loss:0.33515, accu:0.93911, val_accu:0.88587

 epoch:[ 60/100]
  Detector| loss:0.031017, accu:0.98759, val_accu:0.90082
  Proof   | loss:0.32007, accu:0.94327, val_accu:0.86481

 epoch:[ 70/100]
  Detector| loss:0.026182, accu:0.98876, val_accu:0.90285
  Proof   | loss:0.26942, accu:0.9532, val_accu:0.87976

 epoch:[ 80/100]
  Detector| loss:0.025549, accu:0.98927, val_accu:0.8947
  Proof   | loss:0.24004, accu:0.95809, val_accu:0.87432

 epoch:[ 90/100]
  Detector| loss:0.024882, accu:0.99029, val_accu:0.90082
  Proof   | loss:0.22267, accu:0.96028, val_accu:0.87296

 epoch:[100/100]
  Detector| loss:0.023332, accu:0.99102, val_accu:0.91508
  Proof   | loss:0.19653, accu:0.96802, val_accu:0.88383
 examin accuracy:0.9252717

=================================================

examin accuracies: [0.9252717391304348]
examin accu average: 0.9252717391304348
Detector 
acc: [0.920516304347826, 0.920516304347826, 0.9096467391304348, 0.8899456521739131, 0.9028532608695652, 0.9164402173913043, 0.9110054347826086, 0.9252717391304348, 0.9008152173913043, 0.9225543478260869, 0.90625, 0.9137228260869565, 0.8980978260869565, 0.9116847826086957, 0.9028532608695652, 0.9008152173913043, 0.9164402173913043, 0.9008152173913043, 0.9130434782608695, 0.8953804347826086, 0.9123641304347826, 0.9028532608695652, 0.920516304347826, 0.907608695652174, 0.9116847826086957, 0.9089673913043478, 0.904891304347826, 0.8967391304347826, 0.9103260869565217, 0.9096467391304348, 0.9096467391304348, 0.9035326086956522, 0.904891304347826, 0.8994565217391305, 0.9021739130434783, 0.9157608695652174, 0.8987771739130435, 0.8967391304347826, 0.9028532608695652, 0.8885869565217391, 0.9001358695652174, 0.8967391304347826, 0.8987771739130435, 0.8960597826086957, 0.9103260869565217, 0.8987771739130435, 0.8980978260869565, 0.9021739130434783, 0.9028532608695652, 0.8940217391304348, 0.9110054347826086, 0.9069293478260869, 0.9008152173913043, 0.9069293478260869, 0.9014945652173914, 0.9035326086956522, 0.907608695652174, 0.8953804347826086, 0.8994565217391305, 0.9008152173913043, 0.9082880434782609, 0.9089673913043478, 0.9021739130434783, 0.9096467391304348, 0.90625, 0.9137228260869565, 0.9150815217391305, 0.904891304347826, 0.9089673913043478, 0.9028532608695652, 0.907608695652174, 0.8994565217391305, 0.8940217391304348, 0.8953804347826086, 0.9001358695652174, 0.8974184782608695, 0.9055706521739131, 0.9089673913043478, 0.9014945652173914, 0.8947010869565217, 0.90625, 0.8940217391304348, 0.8845108695652174, 0.9008152173913043, 0.9008152173913043, 0.8980978260869565, 0.8980978260869565, 0.8994565217391305, 0.8994565217391305, 0.9008152173913043, 0.9035326086956522, 0.9082880434782609, 0.9089673913043478, 0.907608695652174, 0.9137228260869565, 0.907608695652174, 0.9096467391304348, 0.9150815217391305, 0.9055706521739131, 0.9150815217391305]
loss: [0.3772021308541298, 0.30390465238662523, 0.25891774924141225, 0.22283175434464605, 0.20114555685110738, 0.17386477388371932, 0.15818826476477574, 0.14350765539663973, 0.13116201996872914, 0.12103060943675097, 0.11066588643659776, 0.10834293933933443, 0.10307017913976005, 0.09099183769931442, 0.08698753726659952, 0.08204617890720821, 0.07918244519349292, 0.07553991581591839, 0.07315755976803566, 0.06939255006210966, 0.06839978491134559, 0.06652501919176255, 0.05873387215591567, 0.05878332998956092, 0.055284400647897795, 0.05259015857759933, 0.05264003070563113, 0.05034637059521357, 0.05153747120976587, 0.04662311124690443, 0.04843197407872225, 0.04413739641272641, 0.04229927977426554, 0.04503436421686631, 0.04539845088359717, 0.04461107938550413, 0.037446263360953566, 0.04058468647172814, 0.038127802264910395, 0.03736875526010408, 0.038450842385394354, 0.03652206714312376, 0.039896452716071916, 0.036966378472132876, 0.03020282764613104, 0.03705234500110611, 0.03609398287983049, 0.0332484765591102, 0.032854935389053444, 0.03503788075163059, 0.03723336448595474, 0.03207697028249632, 0.03185158896840816, 0.03511873737472138, 0.030274853809553342, 0.030131009069757447, 0.029639532941006092, 0.02887465648162055, 0.02805691995165935, 0.031016632371056316, 0.03100837833068066, 0.02542486503438697, 0.028082129644572486, 0.025037709510045622, 0.026829915467111685, 0.02679438614366042, 0.026722618321829907, 0.028026432732467497, 0.023641724840961394, 0.026182329459765993, 0.028375488456417047, 0.02467824948521581, 0.024665745991736376, 0.02463867318132645, 0.026713357949885105, 0.025092353710504424, 0.022619052601066975, 0.025429123190275557, 0.024686773636471815, 0.0255486067800911, 0.02504928745013405, 0.02583224186618511, 0.02352941381802456, 0.023412789288780843, 0.024297527238085398, 0.02357567612308596, 0.022247486259308485, 0.023344014730049014, 0.02331173011744075, 0.02488162859125154, 0.028655076430270605, 0.024000776988935397, 0.01890411909692981, 0.019091128643763795, 0.022502422351024752, 0.022000178105668376, 0.020173472209490624, 0.022602666133059727, 0.01863346727965514, 0.023331585427013975]
acc average: 0.9048165760869564
Proof 
acc: [0.7853260869565217, 0.813858695652174, 0.8240489130434783, 0.8491847826086957, 0.8403532608695652, 0.8559782608695652, 0.8586956521739131, 0.8525815217391305, 0.8498641304347826, 0.8546195652173914, 0.8512228260869565, 0.859375, 0.858016304347826, 0.8600543478260869, 0.8566576086956522, 0.8620923913043478, 0.8620923913043478, 0.8573369565217391, 0.8573369565217391, 0.8539402173913043, 0.8743206521739131, 0.8620923913043478, 0.8675271739130435, 0.8525815217391305, 0.8525815217391305, 0.8722826086956522, 0.8634510869565217, 0.8614130434782609, 0.8675271739130435, 0.8641304347826086, 0.8729619565217391, 0.8729619565217391, 0.8743206521739131, 0.8682065217391305, 0.8695652173913043, 0.8722826086956522, 0.8729619565217391, 0.8661684782608695, 0.8722826086956522, 0.8709239130434783, 0.8729619565217391, 0.876358695652174, 0.8838315217391305, 0.8702445652173914, 0.8770380434782609, 0.8790760869565217, 0.8770380434782609, 0.8729619565217391, 0.8777173913043478, 0.8858695652173914, 0.8790760869565217, 0.8722826086956522, 0.8743206521739131, 0.8770380434782609, 0.8716032608695652, 0.8682065217391305, 0.873641304347826, 0.875, 0.8716032608695652, 0.8648097826086957, 0.8729619565217391, 0.8695652173913043, 0.8811141304347826, 0.8688858695652174, 0.8682065217391305, 0.8668478260869565, 0.8702445652173914, 0.873641304347826, 0.8661684782608695, 0.8797554347826086, 0.8729619565217391, 0.8722826086956522, 0.8804347826086957, 0.8790760869565217, 0.8722826086956522, 0.8756793478260869, 0.8872282608695652, 0.876358695652174, 0.8743206521739131, 0.8743206521739131, 0.8783967391304348, 0.8675271739130435, 0.8790760869565217, 0.8756793478260869, 0.8865489130434783, 0.8845108695652174, 0.8817934782608695, 0.8770380434782609, 0.8804347826086957, 0.8729619565217391, 0.8743206521739131, 0.8743206521739131, 0.8824728260869565, 0.8824728260869565, 0.873641304347826, 0.8695652173913043, 0.8783967391304348, 0.889266304347826, 0.8831521739130435, 0.8838315217391305]
loss: [2.968450993578011, 1.5774985897206815, 1.4037757312583032, 1.279939266426541, 1.2223317029877243, 1.2335982641605574, 1.1520017108349043, 1.1704579657204797, 1.1487652148320295, 1.0440468059800496, 0.966305474672362, 0.9120930626152832, 0.8728216419988704, 0.89883412260597, 0.8528423788826739, 0.8606585979322406, 0.8471592100354556, 0.8100719251365305, 0.7831870494323356, 0.7819713596254587, 0.8047872477115314, 0.7569587798876183, 0.7128307501672306, 0.7126286562323292, 0.676024136307571, 0.6529047497173893, 0.5909138166423992, 0.6138470290211316, 0.6004178557484019, 0.5716500131274077, 0.5596720122984636, 0.527287862759745, 0.516199249373836, 0.49248097475757385, 0.4660113398725532, 0.4657341163152846, 0.44201454696915693, 0.4435745385762687, 0.42580687576713405, 0.41987103418333926, 0.4502091465134905, 0.42296668632112655, 0.42584556146638, 0.41056825982180434, 0.3819878675341693, 0.36070102829242423, 0.3543234232760896, 0.35720879519271237, 0.3175016975413277, 0.3351459239966401, 0.37279494801453517, 0.3452011352844501, 0.3350439562971451, 0.358360932495556, 0.3203132813818161, 0.3077885523576085, 0.3286976920055643, 0.32112204524140076, 0.304979252467279, 0.3200682678176814, 0.3168493734428411, 0.3223245241012855, 0.2982337605991514, 0.3089041031399855, 0.2930913468796725, 0.2941007790434235, 0.2873700850759633, 0.2719883107162455, 0.277043153083596, 0.2694218974207173, 0.2639791001081597, 0.26574300314140914, 0.27062055041480954, 0.2636986605982975, 0.25808571353576487, 0.2574257134007307, 0.24302323153307748, 0.2422706595291253, 0.24445608874568586, 0.2400428446540968, 0.24812342542730637, 0.22994938126474698, 0.21120063614112933, 0.2340470164814076, 0.22310001075172048, 0.22413029733804685, 0.22994999499544372, 0.21036148474608313, 0.21372441148631427, 0.22267380827509092, 0.20588910724146556, 0.21817857547155603, 0.2245494868861812, 0.2110345933393784, 0.20504780480087417, 0.20669339497075373, 0.1831645320934487, 0.2042005182322491, 0.2166264616389951, 0.1965327406568041]
Examin
acc average: 0.8687160326086957
