{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from CharToIndex import CharToIndex\n",
    "from MyDatasets import Cross_Validation\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distanced_TenHot_Dataset_set(torch.utils.data.Dataset):\n",
    "    def __init__(self,data,chars_file_path,device=torch.device('cpu')):\n",
    "        self.data = data\n",
    "        self.val_idx = []\n",
    "        self.ans_idx = []\n",
    "        self.char2index = CharToIndex(chars_file_path)\n",
    "        self.length = len(data['answer'])\n",
    "        self.device = device\n",
    "\n",
    "        values = data['value']\n",
    "        for chars in values:\n",
    "            indexes = []\n",
    "            for idx in map(self.char2index.get_index,chars):\n",
    "                indexes.append(idx)\n",
    "            self.val_idx.append(indexes)\n",
    "\n",
    "        answers = data['answer']\n",
    "        for idx in map(self.char2index.get_index,answers):\n",
    "            self.ans_idx.append(idx)\n",
    "\n",
    "\n",
    "        #距離値付きのten_hot_encodeにvalueを変換\n",
    "        distances = data['distance']\n",
    "        self.distanced_ten_hot_encoded_value = np.zeros(shape=(values.shape[0],len(self.char2index)),dtype=np.float32)\n",
    "        for row,indicies in enumerate(self.val_idx):\n",
    "            for id_distance,id_value in enumerate(indicies):\n",
    "                self.distanced_ten_hot_encoded_value[row][id_value]=distances[row][id_distance]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        assert idx < self.length\n",
    "        out_val = self.distanced_ten_hot_encoded_value[idx]\n",
    "\n",
    "        #OCRの第一候補と答えが等しければ１、等しくなければ０\n",
    "        if self.val_idx[idx][0] == self.ans_idx[idx]:\n",
    "            out_ans = 1\n",
    "        else:\n",
    "            out_ans = 0\n",
    "        return torch.tensor(out_val).to(self.device),torch.tensor(out_ans).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_file_path = \"/net/nfs2/export/home/ohno/CR_pytorch/data/tegaki_katsuji/all_chars_3812.npy\"\n",
    "tokens = CharToIndex(chars_file_path)\n",
    "data_file_path = \"/net/nfs2/export/home/ohno/CR_pytorch/data/tegaki_katsuji/tegaki_distance.npz\"\n",
    "data = np.load(data_file_path,allow_pickle=True)\n",
    "\n",
    "EMBEDDING_DIM = 10\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(tokens)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tegaki_dataset = Distanced_TenHot_Dataset_set(data,chars_file_path,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self,encode_size):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(encode_size, 128)\n",
    "    self.fc2 = nn.Linear(128, 2)\n",
    "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    self.to(self.device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_detail(x,y,p):\n",
    "    for _x,_y,_p in zip(x,y,p): #バッチ\n",
    "        #xの表示\n",
    "        for __x in _x:\n",
    "            print(tokens.get_decoded_char(int(__x.item())),end='')\n",
    "        print('\\t\\t(予想、答え)=(',end='')\n",
    "        if _p.item() == 1:\n",
    "            print('〇,',end='')\n",
    "        if _p.item() == 0:\n",
    "            print('Ｘ,',end='')\n",
    "        if _y.item() == 1:\n",
    "            print('〇',end='')\n",
    "        if _y.item() == 0:\n",
    "            print('Ｘ',end='')\n",
    "\n",
    "        if _p.item() == _y.item():\n",
    "            print(')--> 正解')\n",
    "        else:\n",
    "            print(')--> 不正解')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader,learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    batch_size = next(iter(train_dataloader))[0].size(0)\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    model.train()\n",
    "    for i,(x,y) in enumerate(train_dataloader):\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y) #損失計算\n",
    "        prediction = output.data.max(1)[1] #予測結果\n",
    "        accuracy += prediction.eq(y.data).sum().item()/batch_size\n",
    "        optimizer.zero_grad() #勾配初期化\n",
    "        loss.backward(retain_graph=True) #逆伝播\n",
    "        optimizer.step()  #重み更新\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    loss_result = running_loss/len(train_dataloader)\n",
    "    accuracy_result = accuracy/len(train_dataloader)\n",
    "\n",
    "    return loss_result,accuracy_result\n",
    "\n",
    "\n",
    "\n",
    "def eval(model,valid_dataloader,threshold_value,is_show_detail=False):\n",
    "    accuracy = 0\n",
    "    batch_size = next(iter(valid_dataloader))[0].size(0)\n",
    "    confusion_matrix = torch.zeros(2,2)\n",
    "    threshold = torch.full((batch_size,2),threshold_value).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for x,y in valid_dataloader:\n",
    "        output = model(x)\n",
    "        output = F.softmax(output,dim=1)\n",
    "        compare = (output.data > threshold).long()\n",
    "        prediction = compare[:,1] #予測結果\n",
    "        accuracy += prediction.eq(y.data).sum().item()/batch_size\n",
    "\n",
    "        if is_show_detail:\n",
    "          show_detail(x,y,prediction)\n",
    "\n",
    "        for y_true,y_pred in zip(y,prediction):\n",
    "          confusion_matrix[y_true,y_pred]+=1\n",
    "    return accuracy/len(valid_dataloader), confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Examination_Threshold_Value(threshold_value):\n",
    "\n",
    "    cross_validation = Cross_Validation(tegaki_dataset)\n",
    "    k_num = cross_validation.k_num #デフォルトは10\n",
    "    # k_num=1\n",
    "    confusion_matrix = torch.zeros(2,2)\n",
    "\n",
    "    ##学習\n",
    "    for i in range(k_num):\n",
    "        train_dataset,valid_dataset = cross_validation.get_datasets(k_idx=i)\n",
    "\n",
    "        train_dataloader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,drop_last=True) #訓練データのみシャッフル\n",
    "        valid_dataloader=DataLoader(valid_dataset,batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
    "        model = Net(encode_size=len(tokens))\n",
    "\n",
    "        epochs = 100\n",
    "        # epochs = 1\n",
    "\n",
    "\n",
    "        for epoch in range(1,epochs+1):\n",
    "\n",
    "            loss,acc = train(model,train_dataloader,learning_rate=0.01)\n",
    "\n",
    "            valid_acc,conf_mat = eval(model,valid_dataloader,threshold_value)\n",
    "            confusion_matrix += conf_mat\n",
    "\n",
    "    print('Threshold: ',threshold_value)\n",
    "\n",
    "    print(f'confusion matrix: {confusion_matrix}')\n",
    "\n",
    "    tp = confusion_matrix[1][1]\n",
    "    tn = confusion_matrix[0][0]\n",
    "    fp = confusion_matrix[0][1]\n",
    "    fn = confusion_matrix[1][0]\n",
    "\n",
    "    recall_posi = tp/(tp+fn)\n",
    "    precision_posi = tp/(tp+fp)\n",
    "\n",
    "    recall_neg = tn/(tn+fp)\n",
    "    precision_neg = tn/(tn+fn)\n",
    "    print(f'recall_posi:{recall_posi}')\n",
    "    print(f'precision_posi:{precision_posi}')\n",
    "    print(f'recall_neg:{recall_neg}')\n",
    "    print(f'precision_neg:{precision_neg}')\n",
    "\n",
    "    return confusion_matrix,recall_posi,precision_posi,recall_neg,precision_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    result_txt_path = r\"/net/nfs2/export/home/ohno/CR_pytorch/results/detector/detector_with_DTHE.txt\"\n",
    "    with open(result_txt_path,mode='a') as f:\n",
    "        for i in range(90,100):\n",
    "            threshold_value = i*0.01\n",
    "            start = time.time() #開始時間の設定\n",
    "            confusion_matrix,recall_posi,precision_posi,recall_neg,precision_neg = Examination_Threshold_Value(threshold_value)\n",
    "\n",
    "            f.write(f'Threshold: {threshold_value:.3}')\n",
    "            f.write(f' confusion matrix: {confusion_matrix}')\n",
    "            f.write(f' recall_posi:{recall_posi}')\n",
    "            f.write(f' precision_posi:{precision_posi}')\n",
    "            f.write(f' recall_neg:{recall_neg}')\n",
    "            f.write(f' precision_neg:{precision_neg}')\n",
    "            print('実行時間： ',timeSince(start),'\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3f068fdb30bfe91116931ab9f38f90abd8ac3f51d16a38a70c3d538a36b3166"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('CR_pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
